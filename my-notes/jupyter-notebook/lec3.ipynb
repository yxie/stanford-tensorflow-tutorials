{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic models in tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1: assemble our graph\n",
    "\n",
    "Ｓtep 1： read in data\n",
    "\n",
    "Ｓtep 2： create placeholders for inputs and labels\n",
    "\n",
    "`tf.placeholder（dtype, shape=Ｎone, name=Ｎone）`\n",
    "\n",
    "Ｓtep 3： create weight and bias\n",
    "\n",
    "`tf.get_variable（name, shape=Ｎone, dtype=Ｎone, initializer=Ｎone,...)`\n",
    "\n",
    "Step 4: inference\n",
    "\n",
    "`Y_predicted = w * X + b`\n",
    "\n",
    "Step 5: specify loss function\n",
    "\n",
    "* Linear regression (L2 loss): \n",
    "```\n",
    "loss = tf.square(Y - Y_predicted, name='loss')\n",
    "```\n",
    "\n",
    "* Logistic regression (cross-entropy loss): \n",
    "```\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(labels, logits)\n",
    "loss = tf.reduce_mean(entropy)\n",
    "```\n",
    "\n",
    "Step 6: create optimizer\n",
    "\n",
    "`optimizer =tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 2: Train our model\n",
    "Step 1: initialize variables\n",
    "\n",
    "`sess.run(tf.global_variables_initializer())`\n",
    "\n",
    "Step 2: run optimizer\n",
    "\n",
    "`_, loss_ = sess.run([optimizer, loss], feed_dict={X: x, Y: y})`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write log files using a FileWriter\n",
    "\n",
    "`writer = tf.summary.FileWriter('./graphs/linear_reg', tf.get_default_graph())`\n",
    "\n",
    "In terminal\n",
    "```\n",
    "$ python <filename>.py\n",
    "$ tensorboard --logdir='./graphs/linear_reg'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF control flow\n",
    "E.g.: `tf.cond(pred, fn1, fn2, name=None)`\n",
    "```\n",
    "def huber_loss(labels, predictions, delta=14.0):\n",
    "    residual = tf.abs(labels - predictions)\n",
    "    def f1(): return 0.5 * tf.square(residual)\n",
    "    def f2(): return delta * residual - 0.5 * tf.square(delta)\n",
    "    return tf.cond(residual < delta, f1, f2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.data\n",
    "Instead of doing inference with placeholders and feeding in data later, do inference directly with data\n",
    "\n",
    "```\n",
    "tf.data.Dataset\n",
    "tf.data.Iterator\n",
    "```\n",
    "\n",
    "Store data in tf.data.Dataset\n",
    "\n",
    "```\n",
    "tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "tf.data.Dataset.from_generator(gen, output_types, output_shapes)\n",
    "```\n",
    "Can also create dataset from files\n",
    "```\n",
    "tf.data.TextLineDataset(filenames)\n",
    "tf.data.FixedLengthRecorddataset(filenames)\n",
    "tf.data.TFRecordDataset(filenames)\n",
    "```\n",
    "Iterate data\n",
    "```python\n",
    "iterator = dataset.make_one_shot_iterator() \n",
    "# Iterates through the dataset exactly once. No need to initialization.\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "# Iterates through the dataset as many times as we want. Need to initialize with each epoch!\n",
    "```\n",
    "Examples:\n",
    "``` python\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "X, Y = iterator.get_next()\n",
    "...\n",
    "for i in range(100):\n",
    "    sess.run(iterator.initializer)\n",
    "    total_loss = 0\n",
    "    try:\n",
    "        while True:\n",
    "            sess.run([optimizer])\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "```\n",
    "Handling data in tensorflow\n",
    "```python\n",
    "dataset = dataset.shuffle(1000) # return 1000 random samples\n",
    "dataset = dataset.repeat(100) # repeats this dataset 100 times\n",
    "dataset = dataset.batch(128) # combines 128 consecutive elements of this dataset into batches\n",
    "dataset = dataset.map(lambda x: tf.one_hot(x, 10)) # convert to one_hot vector of 10-bit\n",
    "```\n",
    "\n",
    "Should we always use tf.data?\n",
    "* For prototyping, feed dict can be faster and easier to write (pythonic)\n",
    "* tf.data is tricky to use when you have complicated preprocessing or multiple data sources\n",
    "* NLP data is normally just a sequence of integers. In this case, transferring the data over to GPU is pretty quick, so the speedup of tf.data isn't that large\n",
    "\n",
    "\n",
    "How to separate train and test data?\n",
    "```python\n",
    "# define iterator\n",
    "iterator = tf.data.Iterator.from_structure(train_data.output_types, train_data.output_shapes)\n",
    "img, label = iterator.get_next()\n",
    "# define initializers\n",
    "train_init = iterator.make_initializer(train_data)\n",
    "test_init = iterator.make_initializer(test_data)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    ...\n",
    "    for i in range(n_epochs):\n",
    "        # train the model\n",
    "        sess.run(train_init) # run train data initializer\n",
    "        try:\n",
    "            while True:\n",
    "                _, l = sess.run([optimizer, loss]) # fetch optimizer/loss\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        # test the model\n",
    "        sess.run(test_init) # run test data initializer\n",
    "        try:\n",
    "            while True:\n",
    "                sess.run(accuracy) # fetch accuracy\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass                \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers\n",
    "Session looks at all `trainable` variables that loss depends on and update them\n",
    "```\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)\n",
    "_, l = sess.run([optimizer, loss], feed_dict={X: x, Y:y})\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
